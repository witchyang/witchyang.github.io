<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">






<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css">


  <meta name="keywords" content="ML,">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1">






<meta name="description" content="无监督学习无监督学习（Unsupervised Lear{ {ning），顾名思义，就是不受监督的学习，一种自由的学习方式。该学习方式不需要先验知识进行指导，而是不断地自我认知，自我巩固，最后进行自我归纳，在机器学习中，无监督学习可以被简单理解为不为训练集提供对应的类别标识（label），其与有监督学习的对比如下： 有监督学习（Supervised Learning）下的训练集：$ (x^{(1)">
<meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="聚类 Clustering">
<meta property="og:url" content="http://yoursite.com/2018/04/10/week8/index.html">
<meta property="og:site_name" content="葛小野">
<meta property="og:description" content="无监督学习无监督学习（Unsupervised Lear{ {ning），顾名思义，就是不受监督的学习，一种自由的学习方式。该学习方式不需要先验知识进行指导，而是不断地自我认知，自我巩固，最后进行自我归纳，在机器学习中，无监督学习可以被简单理解为不为训练集提供对应的类别标识（label），其与有监督学习的对比如下： 有监督学习（Supervised Learning）下的训练集：$ (x^{(1)">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/04/10/week8/1.png">
<meta property="og:image" content="http://yoursite.com/2018/04/10/week8/2.png">
<meta property="og:updated_time" content="2018-11-13T08:06:42.577Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="聚类 Clustering">
<meta name="twitter:description" content="无监督学习无监督学习（Unsupervised Lear{ {ning），顾名思义，就是不受监督的学习，一种自由的学习方式。该学习方式不需要先验知识进行指导，而是不断地自我认知，自我巩固，最后进行自我归纳，在机器学习中，无监督学习可以被简单理解为不为训练集提供对应的类别标识（label），其与有监督学习的对比如下： 有监督学习（Supervised Learning）下的训练集：$ (x^{(1)">
<meta name="twitter:image" content="http://yoursite.com/2018/04/10/week8/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/04/10/week8/">





  <title>聚类 Clustering | 葛小野</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">葛小野</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">临渊羡鱼不如退而结网</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/10/week8/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="杨玺彤">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/1.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="葛小野">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">聚类 Clustering</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-10T10:14:20+09:00">
                2018-04-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>无监督学习（Unsupervised Lear{ {ning），顾名思义，就是不受监督的学习，一种自由的学习方式。该学习方式不需要先验知识进行指导，而是不断地自我认知，自我巩固，最后进行自我归纳，在机器学习中，无监督学习可以被简单理解为不为训练集提供对应的类别标识（label），其与有监督学习的对比如下：</p>
<p>有监督学习（Supervised Learning）下的训练集：$ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{2})$</p>
<p>无监督学习（Unsupervised Learning）下的训练集：<br>$(x^{(1)}), (x^{(2)}), (x^{(3)})$</p>
<h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><p>在有监督学习中，我们把对样本进行分类的过程称之为分类（Classification），而在无监督学习中，我们将物体被划分到不同集合的过程称之为<strong>聚类（Clustering）</strong>。聚这个动词十分精确，他传神地描绘了各个物体自主地想属于自己的集合靠拢的过程。</p>
<p>在聚类中，我们把物体所在的集合称之为<strong>簇（cluster）</strong>。</p>
<h3 id="K-均值算法-K-Means-Algorithm"><a href="#K-均值算法-K-Means-Algorithm" class="headerlink" title="K-均值算法 K-Means Algorithm"></a>K-均值算法 K-Means Algorithm</h3><p><strong>K-均值</strong>是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。</p>
<p><strong>K-均值</strong>是一个迭代算法，假设我们想要将数据聚类成n个组，其方法为:</p>
<p>首先选择$K$个随机的点，称为<strong>聚类中心</strong>（<strong>cluster centroids</strong>）；</p>
<p>对于数据集中的每一个数据，按照距离$K$个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</p>
<p>计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。</p>
<p>重复步骤2-4直至中心点不再变化。</p>
<p>K-Means 的算法步骤能够简单概括为：</p>
<ol>
<li>分配：样本分配到簇。</li>
<li>移动：移动聚类中心到簇中样本的平均位置。</li>
</ol>
<ul>
<li>注意，某些聚类中心可能没有被分配到样本，这样的聚类中心就会被淘汰（意味着最终的类数可能会减少）。</li>
</ul>
<p><strong>K-均值</strong>算法的伪代码如下：</p>
<ul>
<li>假设簇的个数被定为  K ，样本数为  m。</li>
<li>随机设定  K个聚类中心：$\mu_1,\mu_2,…,\mu_k \in R^n$</li>
</ul>
<p>重复如下过程直至聚类中心的位置不再改变</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Repeat &#123;</span><br><span class="line"></span><br><span class="line">for i = 1 to m</span><br><span class="line"></span><br><span class="line">c(i) := index (form 1 to K) of cluster centroid closest to x(i)</span><br><span class="line"></span><br><span class="line">for k = 1 to K</span><br><span class="line"></span><br><span class="line">μk := average (mean) of points assigned to cluster k</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>算法分为两个步骤:</p>
<ol>
<li><p>第一个<strong>for</strong>循环是赋值步骤，即：对于每一个样例$i$，计算其应该属于的类。for $i=1$ to m：</p>
<script type="math/tex; mode=display">
c^{(i)} = \mbox{距 $x^{(i)}$ 最近的聚类中心}</script><p>距离的计算式如下：<br>$\min_k||x^{(i)}-\mu_k||^2$</p>
</li>
<li><p>第二个<strong>for</strong>循环是聚类中心的移动，即：对于每一个类$K$，重新计算该类的质心。<br>for $k=1$ to $k$:</p>
</li>
</ol>
<script type="math/tex; mode=display">
\mu_k\mbox{（第 $k $个聚类中心的新位置）} = \mbox{第 $k$ 簇的平均位置}</script><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此<br>K-均值的代价函数（又称<strong>畸变函数</strong> <strong>Distortion function</strong>）为：</p>
<script type="math/tex; mode=display">J(c^{(1)},...,c^{(m)},μ_1,...,μ_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{\left( i\right) }-\mu_{c^{(i)}}\right\| ^{2}</script><p>其中${ {\mu }_{ { {c}^{(i)}}}}$代表与${ {x}^{(i)}}$最近的聚类中心点。<br>我们的的优化目标便是找出使得代价函数最小的 $c^{(1)}$,$c^{(2)}$,…,$c^{(m)}$和$μ^1$,$μ^2$,…,$μ^k$.</p>
<p>回顾刚才给出的:<br><strong>K-均值</strong>迭代算法，我们知道，第一个循环是用于减小$c^{(i)}$引起的代价，而第二个循环则是用于减小${ {\mu }_{i}}$引起的代价。迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。</p>
<h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>在运行K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做：</p>
<ol>
<li><p>我们应该选择$K&lt;m$，即聚类中心点的个数要小于所有训练集实例的数量</p>
</li>
<li><p>随机选择$K$个训练实例，然后令$K$个聚类中心分别与这$K$个训练实例相等</p>
</li>
</ol>
<p><strong>K-均值</strong>的一个问题在于，它有可能会停留在一个局部最小值处，而这取决于初始化的情况。</p>
<p>为了解决这个问题，我们通常需要多次运行<strong>K-均值</strong>算法，每一次都重新进行随机初始化，最后再比较多次运行<strong>K-均值</strong>的结果，选择代价函数最小的结果。这种方法在$K$较小的时候（2—10）还是可行的，但是如果$K$较大，这么做也可能不会有明显地改善。</p>
<h3 id="选择聚类数"><a href="#选择聚类数" class="headerlink" title="选择聚类数"></a>选择聚类数</h3><p>实际上，一开始是很难确定聚类数的，但是，也存在一种称之为肘部法则（Elbow Method）的方法来选定适当的K值：</p>
<p><img src="1.png" alt=""></p>
<p>上图左边曲线类似于人的手肘，“肘关节”部分对应的 $ K$值就是最恰当的 $ K$值，但是并不是所有代价函数曲线都存在明显的“肘关节”，例如上图右边曲线。</p>
<p>一般来说，K-Means 得到的聚类结果是服务于我们的后续目的（如通过聚类进行市场分析），所以不能脱离实际而单纯以数学方法来选择$K$值。</p>
<h3 id="二分K-Means算法"><a href="#二分K-Means算法" class="headerlink" title="二分K-Means算法"></a>二分K-Means算法</h3><p>常规的 K-Means 算法的误差通常只能收敛到局部最小，在此，引入一种称为二分 K-Means（bisecting kmeans）的算法，相较于常规的 K-Means，二分 K-Means 不是一来就随机 $K$个聚类中心，而是首先把所有点归为一个簇，然后将该簇一分为二。计算各个所得簇的失真函数（即误差），选择误差最大的簇再进行划分（即最大程度地减少误差），重复该过程直至达到期望的簇数目。</p>
<p>二分 KMeans 算法流程大致如下：</p>
<ol>
<li>初始时，所有样本被看做在同一个簇：<pre><code> $c^{(1)}=c^{(2)}=...=c^{(m)}$
</code></pre></li>
<li>While $num&lt;k$ （$num$表示当前的簇数）:</li>
</ol>
<p>for $i = 1$ to $num$:</p>
<ul>
<li>计算误差</li>
<li>在该簇上进行 K-Means 聚类，其中  k=2</li>
<li>计算将该簇一分为二后的总误差，该误差在之后将会被用于比较</li>
<li>选择使得总误差最小的簇进行划分</li>
</ul>
<p>虽然二分 K-Means 能带来全局最优解，但是我们也可以看到，该算法是一个贪心算法，因此计算量不小。</p>
<h3 id="聚类参考资料"><a href="#聚类参考资料" class="headerlink" title="聚类参考资料"></a>聚类参考资料</h3><p>1.相似度/距离计算方法总结</p>
<p>(1). 闵可夫斯基距离<strong>Minkowski</strong>/（其中欧式距离：$p=2$) </p>
<p>$dist(X,Y)={ {\left( { {\sum\limits_{i=1}^{n}{\left| { {x}_{i}}-{ {y}_{i}} \right|}}^{p}} \right)}^{\frac{1}{p}}}$</p>
<p>(2). 杰卡德相似系数(<strong>Jaccard</strong>)：</p>
<p>$J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}$</p>
<p>(3). 余弦相似度(<strong>cosine similarity</strong>)：</p>
<p>$n$维向量$x$和$y$的夹角记做$\theta$，根据余弦定理，其余弦值为：</p>
<p>$cos (\theta )=\frac{ { {x}^{T}}y}{\left|x \right|\cdot \left| y \right|}=\frac{\sum\limits_{i=1}^{n}{ { {x}_{i}}{ {y}_{i}}}}{\sqrt{\sum\limits_{i=1}^{n}{ { {x}_{i}}^{2}}}\sqrt{\sum\limits_{i=1}^{n}{ { {y}_{i}}^{2}}}}$<br>(4). Pearson皮尔逊相关系数：<br>${ {\rho }_{XY}}=\frac{\operatorname{cov}(X,Y)}{ { {\sigma }_{X}}{ {\sigma }_{Y}}}=\frac{E[(X-{ {\mu }_{X}})(Y-{ {\mu }_{Y}})]}{ { {\sigma }_{X}}{ {\sigma }_{Y}}}=\frac{\sum\limits_{i=1}^{n}{(x-{ {\mu }_{X}})(y-{ {\mu }_{Y}})}}{\sqrt{\sum\limits_{i=1}^{n}{ { {(x-{ {\mu }_{X}})}^{2}}}}\sqrt{\sum\limits_{i=1}^{n}{ { {(y-{ {\mu }_{Y}})}^{2}}}}}$</p>
<p>Pearson相关系数即将$x$、$y$坐标向量各自平移到原点后的夹角余弦。</p>
<p>2.聚类的衡量指标</p>
<p>(1). 均一性：$p$</p>
<p>类似于精确率，一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率(每个 聚簇中正确分类的样本数占该聚簇总样本数的比例和)</p>
<p>(2). 完整性：$r$</p>
<p>类似于召回率，同类别样本被归类到相同簇中，则满足完整性;每个聚簇中正确分类的样本数占该<br>类型的总样本数比例的和</p>
<p>(3). <strong>V-measure</strong>:</p>
<p>均一性和完整性的加权平均 </p>
<p>$V = \frac{(1+\beta^2)<em>pr}{\beta^2</em>p+r}$</p>
<p>(4). 轮廓系数</p>
<p>样本$i$的轮廓系数：$s(i)$</p>
<p>簇内不相似度:计算样本$i$到同簇其它样本的平均距离为$a(i)$，应尽可能小。</p>
<p>簇间不相似度:计算样本$i$到其它簇$C_j$的所有样本的平均距离$b_{ij}$，应尽可能大。</p>
<p>轮廓系数：$s(i)$值越接近1表示样本$i$聚类越合理，越接近-1，表示样本$i$应该分类到 另外的簇中，近似为0，表示样本$i$应该在边界上;所有样本的$s(i)$的均值被成为聚类结果的轮廓系数。 </p>
<p>$s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\}}$</p>
<p>(5). <strong>ARI</strong></p>
<p>数据集$S$共有$N$个元素，  两个聚类结果分别是：</p>
<p>$X=\{ { {X}_{1}},{ {X}_{2}},…,{ {X}_{r}}\},Y=\{ { {Y}_{1}},{ {Y}_{2}},…,{ {Y}_{s}}\}$</p>
<p>$X$和$Y$的元素个数为：</p>
<p>$a=\{ { {a}_{1}},{ {a}_{2}},…,{ {a}_{r}}\},b=\{ { {b}_{1}},{ {b}_{2}},…,{ {b}_{s}}\}$</p>
<p><img src="2.png" alt=""></p>
<p>记：${ {n}_{ij}}=\left| { {X}_{i}}\cap { {Y}_{i}} \right|$</p>
<p>$ARI=\frac{\sum\limits_{i,j}{C_{ { {n}_{ij}}}^{2}}-\left[ \left( \sum\limits_{i}{C_{ { {a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{ { {b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}{\frac{1}{2}\left[ \left( \sum\limits_{i}{C_{ { {a}_{i}}}^{2}} \right)+\left( \sum\limits_{i}{C_{ { {b}_{i}}}^{2}} \right) \right]-\left[ \left( \sum\limits_{i}{C_{ { {a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{ { {b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}$</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>如果觉得对您有帮助，就扫我交个朋友吧！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/2.jpg" alt="杨玺彤 WeChat Pay">
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/3.jpg" alt="杨玺彤 Alipay">
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ML/" rel="tag"># ML</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/05/week7/" rel="next" title="支持向量机">
                <i class="fa fa-chevron-left"></i> 支持向量机
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/30/mathjax_cmdeditor/" rel="prev" title="Markdown 公式总结">
                Markdown 公式总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/1.jpg" alt="杨玺彤">
          <p class="site-author-name" itemprop="name">杨玺彤</p>
           
              <p class="site-description motion-element" itemprop="description">Be better for something</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">60</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2396326053/profile?topnav=1&wvr=6&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/witchyang" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#无监督学习"><span class="nav-number">1.</span> <span class="nav-text">无监督学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#聚类"><span class="nav-number">2.</span> <span class="nav-text">聚类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-均值算法-K-Means-Algorithm"><span class="nav-number">3.</span> <span class="nav-text">K-均值算法 K-Means Algorithm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化"><span class="nav-number">4.</span> <span class="nav-text">优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机初始化"><span class="nav-number">5.</span> <span class="nav-text">随机初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#选择聚类数"><span class="nav-number">6.</span> <span class="nav-text">选择聚类数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二分K-Means算法"><span class="nav-number">7.</span> <span class="nav-text">二分K-Means算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#聚类参考资料"><span class="nav-number">8.</span> <span class="nav-text">聚类参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">杨玺彤</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.staticfile.org/MathJax/MathJax-2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
